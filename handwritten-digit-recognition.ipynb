{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Ajay_Iyer_Lab2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "na_FeqsGdex9",
        "outputId": "c09b711b-c20f-4f30-eee2-95ad8c18a9f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import files, drive\n",
        "drive.mount(\"/content/drive\", force_remount = True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZisXh8ddeyH",
        "outputId": "91114cad-77ac-4f3c-d155-c2e807248e6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# create a cnn model for 10 class digit recognition problem\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class MyCNNNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        # define a convolution layer\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        \n",
        "        # define a pooling layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        # define another convolution layer\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        \n",
        "        # define a dense fully connected feedforward subnetwork\n",
        "        self.fc1 = nn.Linear(16*4*4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        # x -> conv1 -> relu -> pooling -> conv2 -> relu -> pooling -> fully connected\n",
        "        \n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.log_softmax(self.fc3(x))\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]\n",
        "        num_features = 1\n",
        "        \n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "            \n",
        "        return num_features\n",
        "        \n",
        "net = MyCNNNetwork().to(device)\n",
        "print(net)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MyCNNNetwork(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGUnm7rideyP",
        "outputId": "48ec3159-dd49-47a2-df79-6a9d2bb3329a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# retrieve parameters in the network you defined\n",
        "\n",
        "params = list(net.parameters())\n",
        "\n",
        "for i in range(len(params)):\n",
        "    print(params[i].size())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([6, 1, 5, 5])\n",
            "torch.Size([6])\n",
            "torch.Size([16, 6, 5, 5])\n",
            "torch.Size([16])\n",
            "torch.Size([120, 256])\n",
            "torch.Size([120])\n",
            "torch.Size([84, 120])\n",
            "torch.Size([84])\n",
            "torch.Size([10, 84])\n",
            "torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufq4v3ZDdeyW"
      },
      "source": [
        "# define a customized dataset in torch\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# override __init__, __len__, and __getitem__ methods\n",
        "\n",
        "class MNISTDatasets(Dataset):\n",
        "    def __init__(self, dir, transform = None):\n",
        "        self.dir = dir\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        files = glob.glob(self.dir + \"/*.jpg\")[:100]\n",
        "        return len(files)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "            \n",
        "        all_files = glob.glob(self.dir + \"/*.jpg\")[:100]\n",
        "        img_fname = os.path.join(self.dir, all_files[idx])\n",
        "        image = io.imread(img_fname)\n",
        "        \n",
        "        digit = int(self.dir.split(\"/\")[-1].strip())\n",
        "        label = np.array(digit)\n",
        "        sample = {\"image\":image, \"label\":label}\n",
        "        \n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "            \n",
        "        return sample"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et1lOwpqdeyc"
      },
      "source": [
        "# customerized transformation with several operations:\n",
        "# Rescale, ToTensor\n",
        "\n",
        "from skimage import transform\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "class Rescale(object):\n",
        "    def __init__(self, output_size):\n",
        "        assert isinstance(output_size, (int, tuple))\n",
        "        self.output_size = output_size\n",
        "        \n",
        "    def __call__(self, sample):\n",
        "        image, label = sample[\"image\"], sample[\"label\"]\n",
        "        h, w = image.shape[-2:]\n",
        "        \n",
        "        if isinstance(self.output_size, int):\n",
        "            if h > w:\n",
        "                new_h, new_w = self.output_size * h/w, self.output_size\n",
        "            else:\n",
        "                new_h, new_w = self.output_size, self.output_size * w/h\n",
        "        else:\n",
        "            new_h, new_w = self.output_size\n",
        "            \n",
        "        new_h, new_w = int(new_h), int(new_w)\n",
        "        \n",
        "        new_img = transform.resize(image, (new_h, new_w))\n",
        "        \n",
        "        return {\"image\":image, \"label\":label}\n",
        "    \n",
        "class ToTensor(object):\n",
        "    def __call__(self, sample):\n",
        "        image, label = sample[\"image\"], sample[\"label\"]\n",
        "        image = image.reshape((1, image.shape[0], image.shape[1]))\n",
        "        \n",
        "        return {\"image\":torch.from_numpy(image), \"label\":torch.from_numpy(label)}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RahZGxhrdeyj",
        "outputId": "d4cc20da-3afc-46df-8d3d-b25c51164d0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# create data loader for training and validation\n",
        "\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "list_datasets = []\n",
        "\n",
        "for i in range(10):\n",
        "    cur_ds = MNISTDatasets(dir = \"/content/drive/My Drive/MNIST/trainingset/\" + str(i), transform = transforms.Compose([Rescale(28), ToTensor()]))\n",
        "    list_datasets.append(cur_ds)\n",
        "    \n",
        "dataset = torch.utils.data.ConcatDataset(list_datasets)\n",
        "print(len(dataset))\n",
        "\n",
        "train_size = int(len(dataset) * 0.7)\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size, shuffle = True, num_workers = 1)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size, shuffle = True, num_workers = 1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnOkd-bqdeyr",
        "outputId": "8b9a43a2-e620-480e-d52b-81d879ea3add",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Training\n",
        "\n",
        "epochs = 5\n",
        "learning_rate = 1e-3\n",
        "optimizer = optim.Adam(net.parameters(), lr = learning_rate, weight_decay = 1e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    net.train()\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for batch_idx, batch in enumerate(train_dataloader):\n",
        "        inputs, targets = batch[\"image\"].to(device, dtype = torch.float), batch[\"label\"].to(device, dtype = torch.long)\n",
        "        optimizer.zero_grad()\n",
        "        predicted_outputs = net(inputs)\n",
        "        loss = criterion(predicted_outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        if (batch_idx + 1) % 10 == 0:\n",
        "            print(\"epoch: %d, batch: %d, training loss: %0.3f\" % (epoch + 1, batch_idx + 1, running_loss/10))\n",
        "            running_loss = 0.0\n",
        "            \n",
        "    # Validation\n",
        "    \n",
        "    net.eval()\n",
        "    correct = [0.0] * 10\n",
        "    total = [0.0] * 10\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(val_dataloader):\n",
        "            images, labels = batch[\"image\"].to(device, dtype = torch.float), batch[\"label\"].to(device, dtype = torch.long)\n",
        "            predicted_outputs = net(images)\n",
        "            _, predicted_labels = torch.max(predicted_outputs, 1)\n",
        "            c = (predicted_labels == labels)\n",
        "            \n",
        "            for i in range(len(labels)):\n",
        "                label = labels[i]\n",
        "                correct[label] += c[i].item()\n",
        "                total[label] += 1\n",
        "                \n",
        "    for i in range(10):\n",
        "        print(\"\\t Validation accuracy for digit %d: %0.2f\" % (i, 100 * correct[i]/total[i]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 1, batch: 10, training loss: 2.513\n",
            "epoch: 1, batch: 20, training loss: 1.419\n",
            "\t Validation accuracy for digit 0: 100.00\n",
            "\t Validation accuracy for digit 1: 86.67\n",
            "\t Validation accuracy for digit 2: 75.00\n",
            "\t Validation accuracy for digit 3: 60.61\n",
            "\t Validation accuracy for digit 4: 61.54\n",
            "\t Validation accuracy for digit 5: 55.56\n",
            "\t Validation accuracy for digit 6: 43.33\n",
            "\t Validation accuracy for digit 7: 82.14\n",
            "\t Validation accuracy for digit 8: 73.08\n",
            "\t Validation accuracy for digit 9: 82.14\n",
            "epoch: 2, batch: 10, training loss: 0.644\n",
            "epoch: 2, batch: 20, training loss: 0.517\n",
            "\t Validation accuracy for digit 0: 88.89\n",
            "\t Validation accuracy for digit 1: 90.00\n",
            "\t Validation accuracy for digit 2: 69.44\n",
            "\t Validation accuracy for digit 3: 84.85\n",
            "\t Validation accuracy for digit 4: 88.46\n",
            "\t Validation accuracy for digit 5: 55.56\n",
            "\t Validation accuracy for digit 6: 96.67\n",
            "\t Validation accuracy for digit 7: 100.00\n",
            "\t Validation accuracy for digit 8: 38.46\n",
            "\t Validation accuracy for digit 9: 85.71\n",
            "epoch: 3, batch: 10, training loss: 0.286\n",
            "epoch: 3, batch: 20, training loss: 0.356\n",
            "\t Validation accuracy for digit 0: 100.00\n",
            "\t Validation accuracy for digit 1: 90.00\n",
            "\t Validation accuracy for digit 2: 75.00\n",
            "\t Validation accuracy for digit 3: 84.85\n",
            "\t Validation accuracy for digit 4: 88.46\n",
            "\t Validation accuracy for digit 5: 88.89\n",
            "\t Validation accuracy for digit 6: 96.67\n",
            "\t Validation accuracy for digit 7: 100.00\n",
            "\t Validation accuracy for digit 8: 65.38\n",
            "\t Validation accuracy for digit 9: 89.29\n",
            "epoch: 4, batch: 10, training loss: 0.158\n",
            "epoch: 4, batch: 20, training loss: 0.155\n",
            "\t Validation accuracy for digit 0: 96.30\n",
            "\t Validation accuracy for digit 1: 100.00\n",
            "\t Validation accuracy for digit 2: 83.33\n",
            "\t Validation accuracy for digit 3: 75.76\n",
            "\t Validation accuracy for digit 4: 88.46\n",
            "\t Validation accuracy for digit 5: 94.44\n",
            "\t Validation accuracy for digit 6: 90.00\n",
            "\t Validation accuracy for digit 7: 96.43\n",
            "\t Validation accuracy for digit 8: 80.77\n",
            "\t Validation accuracy for digit 9: 96.43\n",
            "epoch: 5, batch: 10, training loss: 0.061\n",
            "epoch: 5, batch: 20, training loss: 0.076\n",
            "\t Validation accuracy for digit 0: 92.59\n",
            "\t Validation accuracy for digit 1: 100.00\n",
            "\t Validation accuracy for digit 2: 88.89\n",
            "\t Validation accuracy for digit 3: 81.82\n",
            "\t Validation accuracy for digit 4: 92.31\n",
            "\t Validation accuracy for digit 5: 91.67\n",
            "\t Validation accuracy for digit 6: 93.33\n",
            "\t Validation accuracy for digit 7: 89.29\n",
            "\t Validation accuracy for digit 8: 96.15\n",
            "\t Validation accuracy for digit 9: 96.43\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}